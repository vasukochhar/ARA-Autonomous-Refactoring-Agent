Autonomous Refactoring Agent (ARA) ğŸ¤–
A Self-Correcting, Human-in-the-Loop Refactoring Engine powered by LangGraph & Gemini.

ARA is not just a code generator; it is a software engineering agent designed to modernize legacy Python codebases. It moves beyond simple "copilots" by implementing a cyclic "Plan-Execute-Verify-Reflect" architecture. It iteratively writes code, runs compilers/linters to detect errors, and self-corrects its own mistakes before asking for human approval.

ğŸš€ Key Features
ğŸ§  Cognitive Architecture: Uses the Reflexion Pattern to "think" about errors. If a refactor fails type checking, the agent analyzes the error log, plans a fix, and retries automatically.

ğŸ”„ Cyclic Self-Correction: Unlike linear chains, ARA uses a stateful graph (LangGraph) that loops until code passes all validation checks (Syntax, Ruff, Pyright) or hits a retry limit.

ğŸ›¡ï¸ Lossless Transformation: Integrates LibCST to ensure refactoring preserves comments, formatting, and project structure (no more "spaghetti code" from LLMs).

ğŸ‘¨â€ğŸ’» Human-in-the-Loop (HITL): "Glass Box" design. The agent pauses at critical decision points, presenting a visual diff for your approval before committing any changes.

ğŸ’¾ Long-Running Persistence: Backed by PostgreSQL, allowing workflows to pause, resume, and survive server restarts without losing context.

ğŸ—ï¸ System Architecture
ARA operates as a 6-node state graph orchestrating the lifecycle of a code change:

Code snippet
graph TD
    User[User Input] --> Analyzer
    Analyzer[ğŸ” Analyzer Node] --> Generator
    Generator[ğŸ“ Generator Node] --> Validator
    Validator[âœ… Validator Node] -->|Pass| HumanReview
    Validator -->|Fail| Reflector
    Reflector[ğŸ¤” Reflector Node] -->|Feedback Loop| Generator
    HumanReview[ğŸ‘¤ Human Review] -->|Approve| Committer
    HumanReview -->|Reject| End
    Committer[ğŸ’¾ Committer Node] --> End[End]
Node Breakdown
Analyzer: Scans the codebase to identify refactoring targets and build a dependency graph.

Generator: Uses Gemini 2.0 Flash to generate improved code or LibCST scripts based on the goal.

Validator: The "System 2" critic. Runs Ruff (linting), Pyright (type checking), and Python compilation checks.

Reflector: Activates on failure. Reads error logs and creates a "critique" to guide the Generator's next attempt.

HumanReview: A persistent interrupt state that waits for user approval via the Web UI.

Committer: Finalizes the change (e.g., creates a PR or writes to disk).

ğŸ› ï¸ Technology Stack
Orchestration: LangGraph

LLM: Google Gemini 2.0 Flash

Backend: FastAPI

Frontend: HTML/JS (served via Python)

Database: PostgreSQL (via Docker)

Static Analysis: Ruff, Pyright, LibCST

âš¡ Getting Started
Prerequisites
Python 3.11+

Docker & Docker Compose

Gemini API Key (Get one here)

1. Installation
Clone the repository and install dependencies:

Bash
git clone https://github.com/vasukochhar/ara.git
cd ara

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install requirements
pip install -r requirements.txt
2. Configuration
Create a .env file in the root directory:

Ini, TOML
GEMINI_API_KEY=your_actual_api_key_here
LLM_MODEL=gemini-2.0-flash
DATABASE_URL=postgresql://user:password@localhost:5432/ara_db
# Debugging flags
MOCK_LLM=false
3. Start the Infrastructure
Launch the PostgreSQL database container:

Bash
docker-compose up -d
4. Run the System
Start the Backend API:

Bash
uvicorn ara.api.main:app --host 127.0.0.1 --port 8000 --reload
Start the Frontend UI:

Bash
python -m http.server 3000 --directory frontend
Access the dashboard at: http://localhost:3000

ğŸ“– Usage Guide
Open the UI: Navigate to http://localhost:3000.

Submit a Task:

Code: Paste your legacy Python code.

Goal: Describe the change (e.g., "Convert this function to use Pydantic models and add docstrings").

Monitor Progress: Watch the agent move through the graph (Analyze -> Generate -> Validate).

Review Changes: If validation passes, a Diff View will appear.

Approve: Applies the changes.

Reject: Stops the workflow.

ğŸ“‚ Project Structure
Plaintext
src/ara/
â”œâ”€â”€ api/            # FastAPI endpoints (main.py)
â”œâ”€â”€ graph/          # LangGraph workflow definition (builder.py)
â”œâ”€â”€ nodes/          # Core logic for each step
â”‚   â”œâ”€â”€ analyzer.py
â”‚   â”œâ”€â”€ generator.py
â”‚   â”œâ”€â”€ validator.py
â”‚   â””â”€â”€ reflector.py
â”œâ”€â”€ state/          # Pydantic state schemas
â”œâ”€â”€ tools/          # File I/O and shell execution tools
â”œâ”€â”€ persistence/    # DB checkpointing logic
â””â”€â”€ provider.py     # LLM configuration
ğŸ›¡ï¸ Production Hardening
We have implemented several resilience features for real-world use:

âœ… Rate Limit Handling: Exponential backoff retry logic (up to 10 retries) for Gemini API calls.

âœ… Fallback Mode: Analyzer and Generator nodes can degrade gracefully if the LLM is temporarily unavailable.

âœ… Validation Bypasses: Configurable flags to bypass strict checks during development/debugging.

âœ… Robust Parsing: Regex-based extractors for handling malformed [SUMMARY] / [CODE] blocks from the LLM.

ğŸ¤ Contributing
Pull requests are welcome! For major changes, please open an issue first to discuss what you would like to change.

ğŸ“„ License
MIT